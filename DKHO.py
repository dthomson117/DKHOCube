import copy
import numpy
import multiprocessing
import matplotlib.pyplot as plt
import cube
import random
from deap import base, algorithms
from deap import creator
from deap import tools

NUM_KRILL = 25
SHUFFLE_AMOUNT = 5
NGEN = 30
LAMBDA = NGEN
CXPB = 0.5
MUTPB = 0.2
EVAL_DEPTH = 3
MIN_MUTATE = 1
MAX_MUTATE = 3

shuffled_cube = cube.Cube(shuffle_amount=SHUFFLE_AMOUNT)


def fitness(depth, individual):
    temp_cube = copy.deepcopy(shuffled_cube)
    temp_cube.run_moves(individual)
    solution = []
    for i in range(depth):
        solve = temp_cube.solve_kociemba()
        if len(solve) < len(solution):
            solution = solve
        elif not solution:
            solution = solve
    if solution == ['']:
        return 0
    else:
        return len(solution),


def mutate(krill, min_mutate=0, max_mutate=0, indpb=0.0):
    if indpb > random.random():
        if len(krill) == 0:
            return krill,
        elif len(krill) == 1:
            mutates = [0]
        elif len(krill) < max_mutate:
            mutates = random.sample(range(0, len(krill), random.randint(min_mutate, len(krill))))
        else:
            try:
                mutates = random.sample(range(0, len(krill), random.randint(min_mutate, max_mutate)))
            except ValueError:
                print("Somethings gone wrong with mutation!")
                raise ValueError

        for index in mutates:
            krill[index] = cube.Cube.random_moves(1)
    return krill,


def move_selection(individual):
    return


def mate(krill1, krill2):
    return krill1, krill2


def init_krill(individual):
    individual = creator.Particle()
    return individual


# This is taken from the DEAP GitHub, I've replicated it here so I can modify it to have move selection for the krill
def eaMuPlusLambdaWithMoveSelection(population, toolbox, mu, lambda_, cxpb, mutpb, ngen,
                                    stats=None, halloffame=None, verbose=__debug__):
    r"""This is the :math:`(\mu + \lambda)` evolutionary algorithm.
    :param population: A list of individuals.
    :param toolbox: A :class:`~deap.base.Toolbox` that contains the evolution
                    operators.
    :param mu: The number of individuals to select for the next generation.
    :param lambda\_: The number of children to produce at each generation.
    :param cxpb: The probability that an offspring is produced by crossover.
    :param mutpb: The probability that an offspring is produced by mutation.
    :param ngen: The number of generation.
    :param stats: A :class:`~deap.tools.Statistics` object that is updated
                  inplace, optional.
    :param halloffame: A :class:`~deap.tools.HallOfFame` object that will
                       contain the best individuals, optional.
    :param verbose: Whether or not to log the statistics.
    :returns: The final population
    :returns: A class:`~deap.tools.Logbook` with the statistics of the
              evolution.
    The algorithm takes in a population and evolves it in place using the
    :func:`varOr` function. It returns the optimized population and a
    :class:`~deap.tools.Logbook` with the statistics of the evolution. The
    logbook will contain the generation number, the number of evaluations for
    each generation and the statistics if a :class:`~deap.tools.Statistics` is
    given as argument. The *cxpb* and *mutpb* arguments are passed to the
    :func:`varOr` function. The pseudocode goes as follow ::
        evaluate(population)
        for g in range(ngen):
            offspring = varOr(population, toolbox, lambda_, cxpb, mutpb)
            evaluate(offspring)
            population = select(population + offspring, mu)
    First, the individuals having an invalid fitness are evaluated. Second,
    the evolutionary loop begins by producing *lambda_* offspring from the
    population, the offspring are generated by the :func:`varOr` function. The
    offspring are then evaluated and the next generation population is
    selected from both the offspring **and** the population. Finally, when
    *ngen* generations are done, the algorithm returns a tuple with the final
    population and a :class:`~deap.tools.Logbook` of the evolution.
    This function expects :meth:`toolbox.mate`, :meth:`toolbox.mutate`,
    :meth:`toolbox.select` and :meth:`toolbox.evaluate` aliases to be
    registered in the toolbox. This algorithm uses the :func:`varOr`
    variation.
    """
    logbook = tools.Logbook()
    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])

    # Evaluate the individuals with an invalid fitness
    invalid_ind = [ind for ind in population if not ind.fitness.valid]
    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)
    for ind, fit in zip(invalid_ind, fitnesses):
        ind.fitness.values = fit

    if halloffame is not None:
        halloffame.update(population)

    record = stats.compile(population) if stats is not None else {}
    logbook.record(gen=0, nevals=len(invalid_ind), **record)
    if verbose:
        print(logbook.stream)

    # Begin the generational process
    for gen in range(1, ngen + 1):
        # Let each krill make a move

        # Vary the population
        offspring = algorithms.varOr(population, toolbox, lambda_, cxpb, mutpb)

        # Evaluate the individuals with an invalid fitness
        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)
        for ind, fit in zip(invalid_ind, fitnesses):
            ind.fitness.values = fit

        # Update the hall of fame with the generated individuals
        if halloffame is not None:
            halloffame.update(offspring)

        # Select the next generation population
        population[:] = toolbox.select(population + offspring, mu)

        # Update the statistics with the new population
        record = stats.compile(population) if stats is not None else {}
        logbook.record(gen=gen, nevals=len(invalid_ind), **record)
        if verbose:
            print(logbook.stream)

    return population, logbook


creator.create("Fitness", base.Fitness, weights=(-1.0,))
creator.create("Particle", list, fitness=creator.Fitness, best=None)
creator.create("Swarm", list, gbest=None, gbestfit=creator.Fitness)

if __name__ == '__main__':
    pool = multiprocessing.Pool()

    toolbox = base.Toolbox()
    toolbox.register("map", pool.map)
    # toolbox.register("attr_item", cube.random_moves, 1)
    toolbox.register("particle", init_krill, creator.Particle)
    toolbox.register("swarm", tools.initRepeat, creator.Swarm, toolbox.particle)

    toolbox.register("mate", mate)
    toolbox.register("mutate", mutate, min_mutate=MIN_MUTATE, max_mutate=MAX_MUTATE, indpb=MUTPB)
    toolbox.register("select", tools.selDoubleTournament, )
    toolbox.register("evaluate", fitness, EVAL_DEPTH)

    swarm = toolbox.swarm(n=NUM_KRILL)

    stats = tools.Statistics(lambda ind: ind.fitness.values)
    stats.register("avg", numpy.mean, axis=0)
    stats.register("std", numpy.std, axis=0)
    stats.register("min", numpy.min, axis=0)
    stats.register("max", numpy.max, axis=0)
    logbook = tools.Logbook()
    hof = tools.HallOfFame(10)

    swarm, logbook = eaMuPlusLambdaWithMoveSelection(swarm, toolbox, NUM_KRILL, LAMBDA, CXPB, MUTPB, NGEN, stats, hof,
                                                     verbose=True)

    gen = logbook.select("gen")
    avgs = logbook.select("avg")
    stds = logbook.select("std")
    avgs_value = [item[0] for item in avgs]
    fig, ax = plt.subplots()
    line = ax.plot(gen, avgs_value)
    ax.set_xlabel("Generation")
    ax.set_ylabel("Fitness (value)")
    plt.show()
